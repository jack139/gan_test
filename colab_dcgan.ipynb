{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"keras_dcgan.ipynb","provenance":[{"file_id":"19WhdS9NfAmxaxsqlDZ0xijzuQV11X_DP","timestamp":1607065694322}],"collapsed_sections":[],"mount_file_id":"1QF4lxiLndgwJTq-Hx5PompnrNSiF2qWw","authorship_tag":"ABX9TyO/YjPzwXU+NdVWORYs7kCG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"htX5tOdohXRq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607648288444,"user_tz":-480,"elapsed":1048,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"9eabcffd-f362-48ea-fd83-ddcdf191b811"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Fri Dec 11 00:58:08 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   50C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1SxBfsTUM6ZS","executionInfo":{"status":"ok","timestamp":1607648291087,"user_tz":-480,"elapsed":1145,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"80aff12d-969a-44c3-f600-cb8335e9eb18"},"source":["%tensorflow_version 1.x"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2iBm7GOAm5Gx","executionInfo":{"status":"ok","timestamp":1607648298774,"user_tz":-480,"elapsed":5711,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"31f2ed34-4e4b-440a-b2cc-06287f837a16"},"source":["!pip3 install gast==0.2.2\n","!pip3 list | grep gast"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=5714323878aa6ff1857c4975b6d900d7b293934f32e70faba5bbb07b23d5ab7d\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","Installing collected packages: gast\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","Successfully installed gast-0.2.2\n","gast                          0.2.2          \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d_Hzk3elhcav","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607648308709,"user_tz":-480,"elapsed":7418,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"f51d0199-3c04-43ec-d653-18e0c71262c9"},"source":["import tensorflow.compat.v1 as tf\n","print(tf.__version__)\n","print(tf.test.is_gpu_available())\n","import keras\n","print(keras.__version__)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["1.15.2\n","True\n","2.3.1\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"YYHmTXCkTv6m","executionInfo":{"status":"ok","timestamp":1607648349044,"user_tz":-480,"elapsed":1110,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}}},"source":["import os\n","os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n","\n","# AMP要使用 tf.keras \n","os.environ[\"TF_KERAS\"] = \"1\""],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"J5a_wJkeDEQu","executionInfo":{"status":"ok","timestamp":1607648351506,"user_tz":-480,"elapsed":1196,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}}},"source":["# coding=utf-8\n","\n","import os\n","from distutils.util import strtobool\n","\n","# 判断是tf.keras还是纯keras的标记\n","is_tf_keras = strtobool(os.environ.get('TF_KERAS', '0'))\n","\n","if is_tf_keras:\n","    from tensorflow.keras import backend as K\n","else:\n","    from keras import backend as K\n","\n","import numpy as np\n","import imageio\n","\n","\n","# 采样函数\n","def sample(path, g_model, img_dim, z_dim, n=9, z_samples=None):\n","    figure = np.zeros((img_dim * n, img_dim * n, 3))\n","    if z_samples is None:\n","        z_samples = np.random.randn(n**2, z_dim)\n","    for i in range(n):\n","        for j in range(n):\n","            z_sample = z_samples[[i * n + j]]\n","            x_sample = g_model.predict(z_sample)\n","            digit = x_sample[0]\n","            figure[i * img_dim:(i + 1) * img_dim,\n","                   j * img_dim:(j + 1) * img_dim] = digit\n","    figure = (figure + 1) / 2 * 255\n","    figure = np.round(figure, 0).astype(np.uint8)\n","    imageio.imwrite(path, figure)\n","\n","\n","# 谱归一化\n","class SpectralNormalization:\n","    \"\"\"层的一个包装，用来加上SN。\n","    \"\"\"\n","\n","    def __init__(self, layer):\n","        self.layer = layer\n","\n","    def spectral_norm(self, w, r=5):\n","        w_shape = K.int_shape(w)\n","        in_dim = np.prod(w_shape[:-1]).astype(int)\n","        out_dim = w_shape[-1]\n","        w = K.reshape(w, (in_dim, out_dim))\n","        u = K.ones((1, in_dim))\n","        for i in range(r):\n","            v = K.l2_normalize(K.dot(u, w))\n","            u = K.l2_normalize(K.dot(v, K.transpose(w)))\n","        return K.sum(K.dot(K.dot(u, w), K.transpose(v)))\n","\n","    def spectral_normalization(self, w):\n","        return w / self.spectral_norm(w)\n","\n","    def __call__(self, inputs):\n","        with K.name_scope(self.layer.name):\n","            if not self.layer.built:\n","                input_shape = K.int_shape(inputs)\n","                self.layer.build(input_shape)\n","                self.layer.built = True\n","                if self.layer._initial_weights is not None:\n","                    self.layer.set_weights(self.layer._initial_weights)\n","        if not hasattr(self.layer, 'spectral_normalization'):\n","            if hasattr(self.layer, 'kernel'):\n","                self.layer.kernel = self.spectral_normalization(self.layer.kernel)\n","            if hasattr(self.layer, 'gamma'):\n","                self.layer.gamma = self.spectral_normalization(self.layer.gamma)\n","            self.layer.spectral_normalization = True\n","        return self.layer(inputs)\n","\n","\n","class ExponentialMovingAverage:\n","    \"\"\"对模型权重进行指数滑动平均。\n","    用法：在model.compile之后、第一次训练之前使用；\n","    先初始化对象，然后执行inject方法。\n","\n","    训练：\n","    EMAer = ExponentialMovingAverage(model) # 在模型compile之后执行\n","    EMAer.initialize() # 在模型compile之后执行\n","    EMAer.ema_on_batch() # 每个batch完成后执行\n","\n","    预测：\n","    EMAer.apply_ema_weights() # 将EMA的权重应用到模型中\n","    model.predict(x_test) # 进行预测、验证、保存等操作\n","\n","    继续训练：\n","    EMAer.reset_old_weights() # 继续训练之前，要恢复模型旧权重。还是那句话，EMA不影响模型的优化轨迹。\n","    \"\"\"\n","    def __init__(self, model, momentum=0.999):\n","        self.momentum = momentum\n","        self.model = model\n","    def inject(self):\n","        \"\"\"与旧代码兼容\n","        \"\"\"\n","        self.initialize()\n","    def initialize(self):\n","        \"\"\"ema_weights初始化跟原模型初始化一致。\n","        \"\"\"\n","        self.old_weights = K.batch_get_value(self.model.weights)\n","        self.mv_trainable_weights_vals = {x.name: K.get_value(x) for x in\n","                                          self.model.trainable_weights}\n","    def apply_ema_weights(self):\n","        \"\"\"备份原模型权重，然后将平均权重应用到模型上去。\n","        \"\"\"\n","        self.old_weights = K.batch_get_value(self.model.weights)\n","        for weight in self.model.trainable_weights:\n","             K.set_value(weight, self.mv_trainable_weights_vals[weight.name])\n","    def reset_old_weights(self):\n","        \"\"\"恢复模型到旧权重。\n","        \"\"\"\n","        K.batch_set_value(zip(self.model.weights, self.old_weights))\n","    def ema_on_batch(self):\n","        for weight in self.model.trainable_weights:\n","            old_val = self.mv_trainable_weights_vals[weight.name]\n","            self.mv_trainable_weights_vals[weight.name] -= \\\n","                (1.0 - self.momentum) * (old_val - K.get_value(weight))\n","\n","\n","class ExponentialMovingAverage_NEED_Keras_patch:\n","    \"\"\"对模型权重进行指数滑动平均。\n","    用法：在model.compile之后、第一次训练之前使用；\n","    先初始化对象，然后执行inject方法。\n","\n","    训练：\n","    EMAer = ExponentialMovingAverage(model) # 在模型compile之后执行\n","    EMAer.inject() # 在模型compile之后执行\n","    model.fit(x_train, y_train) # 训练模型\n","\n","    预测：\n","    EMAer.apply_ema_weights() # 将EMA的权重应用到模型中\n","    model.predict(x_test) # 进行预测、验证、保存等操作\n","\n","    继续训练：\n","    EMAer.reset_old_weights() # 继续训练之前，要恢复模型旧权重。还是那句话，EMA不影响模型的优化轨迹。\n","    model.fit(x_train, y_train) # 继续训练\n","    \"\"\"\n","    '''\n","    权重滑动平均 EMA （需要给Keras 2.3.1打个补丁，才能生效） \n","    diff --git a/keras/engine/training.py b/keras/engine/training.py\n","    index 0a556f21..1a9a374e 100644\n","    --- a/keras/engine/training.py\n","    +++ b/keras/engine/training.py\n","    @@ -328,7 +328,7 @@ class Model(Network):\n","                     self.train_function = K.function(\n","                         inputs,\n","                         [self.total_loss] + metrics_tensors,\n","    -                    updates=updates + metrics_updates,\n","    +                    updates=updates + metrics_updates + (self._other_metrics if hasattr(self, '_other_metrics') else []),\n","                         name='train_function',\n","                         **self._function_kwargs)\n","    '''\n","    def __init__(self, model, momentum=0.999):\n","        self.momentum = momentum\n","        self.model = model\n","        self.ema_weights = [K.zeros(K.shape(w)) for w in model.weights]\n","    def inject(self):\n","        \"\"\"添加更新算子到model.metrics_updates。 \n","        \"\"\"\n","        self.initialize()\n","        for w1, w2 in zip(self.ema_weights, self.model.weights):\n","            op = K.moving_average_update(w1, w2, self.momentum)\n","            #self.model.metrics_updates.append(op) # 在 keras 2.2.4 有效\n","            if not hasattr(self.model, '_other_metrics'):\n","                self.model._other_metrics = []\n","            self.model._other_metrics.append(op)\n","    def initialize(self):\n","        \"\"\"ema_weights初始化跟原模型初始化一致。\n","        \"\"\"\n","        self.old_weights = K.batch_get_value(self.model.weights)\n","        K.batch_set_value(zip(self.ema_weights, self.old_weights))\n","    def apply_ema_weights(self):\n","        \"\"\"备份原模型权重，然后将平均权重应用到模型上去。\n","        \"\"\"\n","        self.old_weights = K.batch_get_value(self.model.weights)\n","        ema_weights = K.batch_get_value(self.ema_weights)\n","        K.batch_set_value(zip(self.model.weights, ema_weights))\n","    def reset_old_weights(self):\n","        \"\"\"恢复模型到旧权重。\n","        \"\"\"\n","        K.batch_set_value(zip(self.model.weights, self.old_weights))\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"6nDDrZxZbZIA","executionInfo":{"status":"ok","timestamp":1607648360928,"user_tz":-480,"elapsed":1186,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}}},"source":["#! -*- coding: utf-8 -*-\n","\n","import os\n","from distutils.util import strtobool\n","\n","# 判断是tf.keras还是纯keras的标记\n","is_tf_keras = strtobool(os.environ.get('TF_KERAS', '0'))\n","\n","if is_tf_keras:\n","    from tensorflow.keras.layers import *\n","    from tensorflow.keras.models import Model\n","    from tensorflow.keras import backend as K\n","else:\n","    from keras.layers import *\n","    from keras.models import Model\n","    from keras import backend as K\n","\n","import numpy as np\n","#from utils import SpectralNormalization\n","\n","\n","class ScaleShift(Layer):\n","    \"\"\"平移缩放\n","    \"\"\"\n","    def __init__(self, **kwargs):\n","        super(ScaleShift, self).__init__(**kwargs)\n","    def call(self, inputs):\n","        z, beta, gamma = inputs\n","        for i in range(K.ndim(z) - 2):\n","            beta = K.expand_dims(beta, 1)\n","            gamma = K.expand_dims(gamma, 1)\n","        return z * (gamma + 1) + beta\n","\n","# SELF-MODE\n","def SelfModulatedBatchNormalization(h, c, z_dim):\n","    num_hidden = z_dim\n","    dim = K.int_shape(h)[-1]\n","    h = BatchNormalization(center=False, scale=False)(h)\n","    beta = Dense(num_hidden, activation='relu')(c)\n","    beta = Dense(dim)(beta)\n","    gamma = Dense(num_hidden, activation='relu')(c)\n","    gamma = Dense(dim)(gamma)\n","    return ScaleShift()([h, beta, gamma])\n","\n","\n","# 生成器和判别器 模型\n","def load_model(img_dim, z_dim, activation=None, sn=False, use_bias=True, self_mode=False):\n","    num_layers = int(np.log2(img_dim)) - 3\n","    if img_dim > 256:\n","        max_num_channels = img_dim * 4\n","    else:    \n","        max_num_channels = img_dim * 8\n","    f_size = img_dim // 2**(num_layers + 1)\n","\n","    # 谱归一化\n","    if sn:\n","        SN = SpectralNormalization\n","    else:\n","        SN = lambda xx: xx\n","\n","    # 判别器\n","    x_in = Input(shape=(img_dim, img_dim, 3))\n","    x = x_in\n","\n","    for i in range(num_layers + 1):\n","        num_channels = max_num_channels // 2**(num_layers - i)\n","        x = SN(Conv2D(num_channels,\n","                   (4, 4),\n","                   strides=(2, 2),\n","                   use_bias=use_bias,\n","                   padding='same'))(x)\n","        if i > 0:\n","            x = SN(BatchNormalization())(x)\n","        x = LeakyReLU(0.2)(x)\n","\n","    x = Flatten()(x)\n","    x = SN(Dense(1, use_bias=use_bias, activation=activation))(x)\n","\n","    d_model = Model(x_in, x)\n","\n","\n","    # 生成器\n","    z_in = Input(shape=(z_dim, ))\n","    z = z_in\n","\n","    z = Dense(f_size**2 * max_num_channels)(z)\n","    z = Reshape((f_size, f_size, max_num_channels))(z)\n","    if self_mode: # SELF-MODE\n","        z = SelfModulatedBatchNormalization(z, z_in, z_dim)\n","    else:\n","        z = BatchNormalization()(z)\n","    z = Activation('relu')(z)\n","\n","    for i in range(num_layers):\n","        num_channels = max_num_channels // 2**(i + 1)\n","        z = Conv2DTranspose(num_channels,\n","                            (4, 4),\n","                            strides=(2, 2),\n","                            padding='same')(z)\n","        if self_mode:  # SELF-MODE\n","            z = SelfModulatedBatchNormalization(z, z_in, z_dim)\n","        else:\n","            z = BatchNormalization()(z)\n","        z = Activation('relu')(z)\n","\n","    z = Conv2DTranspose(3,\n","                        (4, 4),\n","                        strides=(2, 2),\n","                        padding='same')(z)\n","    z = Activation('tanh')(z)\n","\n","    g_model = Model(z_in, z)\n","\n","    return d_model, g_model\n","\n","\n","\n","# 生成器和判别器 模型\n","def load_model_2(img_dim, z_dim, activation=None, sn=False, use_bias=True):\n","    num_layers = int(np.log2(img_dim)) - 3\n","    if img_dim > 256:\n","        max_num_channels = img_dim * 4\n","    else:    \n","        max_num_channels = img_dim * 8\n","    f_size = img_dim // 2**(num_layers + 1)\n","\n","    # 谱归一化\n","    if sn:\n","        SN = SpectralNormalization\n","    else:\n","        SN = lambda xx: xx\n","\n","    # 判别器\n","    x_in = Input(shape=(img_dim, img_dim, 3))\n","    x = x_in\n","\n","    x = SN(Conv2D(128, 3))(x)\n","    x = LeakyReLU()(x)\n","    x = SN(Conv2D(128, 4, strides=2))(x)\n","    x = LeakyReLU()(x)\n","    x = SN(Conv2D(128, 4, strides=2))(x)\n","    x = LeakyReLU()(x)\n","    x = SN(Conv2D(128, 4, strides=2))(x)\n","    x = LeakyReLU()(x)\n","    x = Flatten()(x)\n","    x = Dropout(0.4)(x)\n","    x = SN(Dense(1, use_bias=use_bias, activation=activation))(x)\n","\n","    d_model = Model(x_in, x)\n","\n","    # 生成器\n","    z_in = Input(shape=(z_dim, ))\n","    z = z_in\n","\n","    z = Dense(128 * (img_dim//2) * (img_dim//2))(z_in)\n","    z = LeakyReLU()(z)\n","    z = Reshape((img_dim//2, img_dim//2, 128))(z)\n","    z = Conv2D(128, 4, padding='same')(z)\n","    z = LeakyReLU()(z)\n","    z = Conv2DTranspose(128, 4, strides=2, padding='same')(z)\n","    z = LeakyReLU()(z)\n","    z = Conv2D(128, 4, padding='same')(z)\n","    z = LeakyReLU()(z)\n","    z = Conv2D(128, 4, padding='same')(z)\n","    z = LeakyReLU()(z)\n","    z = Conv2D(3, 7, activation='tanh', padding='same')(z)\n","\n","    g_model = Model(z_in, z)\n","\n","\n","    return d_model, g_model\n","\n","\n","# 生成器和判别器 模型\n","def load_model_3(img_dim, z_dim, activation=None, sn=False, use_bias=True):\n","    num_layers = int(np.log2(img_dim)) - 3\n","    if img_dim > 256:\n","        max_num_channels = img_dim * 4\n","    else:    \n","        max_num_channels = img_dim * 8\n","    f_size = img_dim // 2**(num_layers + 1)\n","\n","    # 谱归一化\n","    if sn:\n","        SN = SpectralNormalization\n","    else:\n","        SN = lambda xx: xx\n","\n","    # 判别器\n","    x_in = Input(shape=(img_dim, img_dim, 3))\n","    x = x_in\n","\n","    x = SN(Conv2D(64, 3, strides=2, padding='same'))(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","    x = Dropout(0.25)(x)\n","    x = SN(Conv2D(128, 3, strides=2, padding='same'))(x)\n","    x = ZeroPadding2D(padding=((0,1),(0,1)))(x)\n","    x = SN(BatchNormalization(momentum=0.8))(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","    x = Dropout(0.25)(x)\n","    x = SN(Conv2D(256, 3, strides=2, padding='same'))(x)\n","    x = SN(BatchNormalization(momentum=0.8))(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","    x = Dropout(0.25)(x)\n","    x = SN(Conv2D(512, 3, strides=2, padding='same'))(x)\n","    x = SN(BatchNormalization(momentum=0.8))(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","    x = Dropout(0.25)(x)\n","    x = Flatten()(x)\n","    x = SN(Dense(1, use_bias=use_bias, activation=activation))(x)\n","\n","    d_model = Model(x_in, x)\n","\n","    # 生成器\n","    z_in = Input(shape=(z_dim, ))\n","    z = z_in\n","\n","    z = Dense(128 * (img_dim//4) * (img_dim//4))(z_in)\n","    z = LeakyReLU(alpha=0.2)(z)\n","    z = Reshape((img_dim//4, img_dim//4, 128))(z)\n","    z = UpSampling2D()(z)\n","    z = Conv2D(128, 4, padding='same')(z)\n","    z = BatchNormalization(momentum=0.8)(z)\n","    z = LeakyReLU(alpha=0.2)(z)\n","    z = UpSampling2D()(z)\n","    z = Conv2D(64, 4, padding='same')(z)\n","    z = BatchNormalization(momentum=0.8)(z)\n","    z = LeakyReLU(alpha=0.2)(z)\n","    z = Conv2D(3, 7, activation='tanh', padding='same')(z)\n","\n","    g_model = Model(z_in, z)\n","\n","\n","    return d_model, g_model\n","\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4PvicOWhfsF","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1607682440090,"user_tz":-480,"elapsed":50707,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"e2827fc1-4375-4251-d7a3-b71c2e597355"},"source":["#! -*- coding: utf-8 -*-\n","import os\n","os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n","\n","# AMP要使用 tf.keras \n","os.environ[\"TF_KERAS\"] = \"1\"\n","\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","#from utils import sample, ExponentialMovingAverage\n","#from models import load_model\n","\n","\n","if not os.path.exists('samples'):\n","    os.mkdir('samples')\n","\n","\n","img_dim = 256\n","z_dim = 100\n","EMA = True # whether use EMA\n","L1_or_L2 = 'L1' #  L1 或 L2\n","total_iter = 1000000\n","batch_size = 128\n","iters_per_sample = 100 # 采样频率\n","\n","\n","img_dir = '/content/CASIA-maxpy-clean'\n","\n","# 数据生成器\n","img_datagen = ImageDataGenerator(\n","    preprocessing_function=lambda x: x.astype(np.float32) / 255 * 2 - 1,\n","    zoom_range=0.0 # 缩放， 0.5 放大\n",")\n","img_generator = img_datagen.flow_from_directory(\n","    img_dir,\n","    target_size=(img_dim, img_dim),\n","    batch_size=batch_size,\n","    class_mode=None # 只生成图片，不生成标签\n",")\n","\n","\n","# 载入基本模型： 判别器，生成器\n","d_model, g_model = load_model(img_dim, z_dim, use_bias=False, self_mode=True)\n","d_model.summary()\n","g_model.summary()\n","\n","# AMP 混合精度\n","opt = Adam(2e-4, 0.5)\n","opt = tf.train.experimental.enable_mixed_precision_graph_rewrite(opt)\n","\n","# 整合模型（训练判别器）\n","x_in = Input(shape=(img_dim, img_dim, 3))\n","z_in = Input(shape=(z_dim, ))\n","g_model.trainable = False\n","\n","x_real = x_in\n","x_fake = g_model(z_in)\n","\n","x_real_score = d_model(x_real)\n","x_fake_score = d_model(x_fake)\n","\n","d_train_model = Model([x_in, z_in],\n","                      [x_real_score, x_fake_score])\n","\n","d_loss = x_real_score - x_fake_score\n","d_loss = d_loss[:, 0]\n","if L1_or_L2=='L1':\n","    d_norm = 10 * K.mean(K.abs(x_real - x_fake), axis=[1, 2, 3])\n","else:\n","    d_norm = 10 * K.sqrt(K.mean(K.square(x_real - x_fake), axis=[1, 2, 3]))\n","d_loss = K.mean(- d_loss + 0.5 * d_loss**2 / d_norm)\n","\n","d_train_model.add_loss(d_loss)\n","d_train_model.compile(optimizer=opt)\n","\n","\n","# 整合模型（训练生成器）\n","g_model.trainable = True\n","d_model.trainable = False\n","\n","x_real = x_in\n","x_fake = g_model(z_in)\n","\n","x_real_score = d_model(x_real)\n","x_fake_score = d_model(x_fake)\n","\n","g_train_model = Model([x_in, z_in],\n","                      [x_real_score, x_fake_score])\n","\n","g_loss = K.mean(x_real_score - x_fake_score)\n","\n","g_train_model.add_loss(g_loss)\n","g_train_model.compile(optimizer=opt)\n","\n","\n","# 检查模型结构\n","d_train_model.summary()\n","g_train_model.summary()\n","\n","\n","# 装入checkpoints， 只保存了生成模型的权重\n","g_train_model.load_weights('out/g_train_ema_model.weights')\n","g_model = g_train_model.layers[2]\n","d_model = g_train_model.layers[3]\n","\n","# EMA\n","if EMA:\n","    EMAer_g_train = ExponentialMovingAverage(g_train_model, 0.999) # 在模型compile之后执行\n","    EMAer_g_train.inject() # 在模型compile之后执行\n","\n","\n","if __name__ == '__main__':\n","\n","\n","    n_size = 6\n","    Z = np.random.randn(n_size**2, z_dim)\n","\n","    for i in range(total_iter):\n","        for j in range(2):\n","            x_sample = next(img_generator)\n","            z_sample = np.random.randn(len(x_sample), z_dim)\n","            d_loss = d_train_model.train_on_batch(\n","                [x_sample, z_sample], None)\n","        for j in range(1):\n","            x_sample = next(img_generator)\n","            z_sample = np.random.randn(len(x_sample), z_dim)\n","            g_loss = g_train_model.train_on_batch(\n","                [x_sample, z_sample], None)\n","            if EMA:\n","                EMAer_g_train.ema_on_batch()\n","        if i % 10 == 0:\n","            print('iter: %s, d_loss: %s, g_loss: %s' % (i, d_loss, g_loss))\n","        if i % iters_per_sample == 0:\n","            sample('samples/test_%s.png' % i, g_model, img_dim, z_dim, n=n_size, z_samples=Z)\n","            g_train_model.save_weights('./g_train_model.weights')\n","            if EMA:\n","                EMAer_g_train.apply_ema_weights() # 将EMA的权重应用到模型中\n","                sample('samples/test_ema_%s.png' % i, g_model, img_dim, z_dim, n=n_size, z_samples=Z)\n","                g_train_model.save_weights('./g_train_ema_model.weights')\n","                EMAer_g_train.reset_old_weights() # 继续训练之前，要恢复模型旧权重\n"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Found 2412 images belonging to 82 classes.\n","Model: \"model_20\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_21 (InputLayer)        [(None, 256, 256, 3)]     0         \n","_________________________________________________________________\n","conv2d_28 (Conv2D)           (None, 128, 128, 64)      3072      \n","_________________________________________________________________\n","leaky_re_lu_28 (LeakyReLU)   (None, 128, 128, 64)      0         \n","_________________________________________________________________\n","conv2d_29 (Conv2D)           (None, 64, 64, 128)       131072    \n","_________________________________________________________________\n","batch_normalization_51 (Batc (None, 64, 64, 128)       512       \n","_________________________________________________________________\n","leaky_re_lu_29 (LeakyReLU)   (None, 64, 64, 128)       0         \n","_________________________________________________________________\n","conv2d_30 (Conv2D)           (None, 32, 32, 256)       524288    \n","_________________________________________________________________\n","batch_normalization_52 (Batc (None, 32, 32, 256)       1024      \n","_________________________________________________________________\n","leaky_re_lu_30 (LeakyReLU)   (None, 32, 32, 256)       0         \n","_________________________________________________________________\n","conv2d_31 (Conv2D)           (None, 16, 16, 512)       2097152   \n","_________________________________________________________________\n","batch_normalization_53 (Batc (None, 16, 16, 512)       2048      \n","_________________________________________________________________\n","leaky_re_lu_31 (LeakyReLU)   (None, 16, 16, 512)       0         \n","_________________________________________________________________\n","conv2d_32 (Conv2D)           (None, 8, 8, 1024)        8388608   \n","_________________________________________________________________\n","batch_normalization_54 (Batc (None, 8, 8, 1024)        4096      \n","_________________________________________________________________\n","leaky_re_lu_32 (LeakyReLU)   (None, 8, 8, 1024)        0         \n","_________________________________________________________________\n","conv2d_33 (Conv2D)           (None, 4, 4, 2048)        33554432  \n","_________________________________________________________________\n","batch_normalization_55 (Batc (None, 4, 4, 2048)        8192      \n","_________________________________________________________________\n","leaky_re_lu_33 (LeakyReLU)   (None, 4, 4, 2048)        0         \n","_________________________________________________________________\n","flatten_5 (Flatten)          (None, 32768)             0         \n","_________________________________________________________________\n","dense_122 (Dense)            (None, 1)                 32768     \n","=================================================================\n","Total params: 44,747,264\n","Trainable params: 44,739,328\n","Non-trainable params: 7,936\n","_________________________________________________________________\n","Model: \"model_21\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_22 (InputLayer)           [(None, 100)]        0                                            \n","__________________________________________________________________________________________________\n","dense_123 (Dense)               (None, 32768)        3309568     input_22[0][0]                   \n","__________________________________________________________________________________________________\n","reshape_5 (Reshape)             (None, 4, 4, 2048)   0           dense_123[0][0]                  \n","__________________________________________________________________________________________________\n","dense_124 (Dense)               (None, 100)          10100       input_22[0][0]                   \n","__________________________________________________________________________________________________\n","dense_126 (Dense)               (None, 100)          10100       input_22[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_56 (BatchNo (None, 4, 4, 2048)   4096        reshape_5[0][0]                  \n","__________________________________________________________________________________________________\n","dense_125 (Dense)               (None, 2048)         206848      dense_124[0][0]                  \n","__________________________________________________________________________________________________\n","dense_127 (Dense)               (None, 2048)         206848      dense_126[0][0]                  \n","__________________________________________________________________________________________________\n","scale_shift_28 (ScaleShift)     (None, 4, 4, 2048)   0           batch_normalization_56[0][0]     \n","                                                                 dense_125[0][0]                  \n","                                                                 dense_127[0][0]                  \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 4, 4, 2048)   0           scale_shift_28[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_transpose_28 (Conv2DTran (None, 8, 8, 1024)   33555456    activation_33[0][0]              \n","__________________________________________________________________________________________________\n","dense_128 (Dense)               (None, 100)          10100       input_22[0][0]                   \n","__________________________________________________________________________________________________\n","dense_130 (Dense)               (None, 100)          10100       input_22[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_57 (BatchNo (None, 8, 8, 1024)   2048        conv2d_transpose_28[0][0]        \n","__________________________________________________________________________________________________\n","dense_129 (Dense)               (None, 1024)         103424      dense_128[0][0]                  \n","__________________________________________________________________________________________________\n","dense_131 (Dense)               (None, 1024)         103424      dense_130[0][0]                  \n","__________________________________________________________________________________________________\n","scale_shift_29 (ScaleShift)     (None, 8, 8, 1024)   0           batch_normalization_57[0][0]     \n","                                                                 dense_129[0][0]                  \n","                                                                 dense_131[0][0]                  \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 8, 8, 1024)   0           scale_shift_29[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_transpose_29 (Conv2DTran (None, 16, 16, 512)  8389120     activation_34[0][0]              \n","__________________________________________________________________________________________________\n","dense_132 (Dense)               (None, 100)          10100       input_22[0][0]                   \n","__________________________________________________________________________________________________\n","dense_134 (Dense)               (None, 100)          10100       input_22[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_58 (BatchNo (None, 16, 16, 512)  1024        conv2d_transpose_29[0][0]        \n","__________________________________________________________________________________________________\n","dense_133 (Dense)               (None, 512)          51712       dense_132[0][0]                  \n","__________________________________________________________________________________________________\n","dense_135 (Dense)               (None, 512)          51712       dense_134[0][0]                  \n","__________________________________________________________________________________________________\n","scale_shift_30 (ScaleShift)     (None, 16, 16, 512)  0           batch_normalization_58[0][0]     \n","                                                                 dense_133[0][0]                  \n","                                                                 dense_135[0][0]                  \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 16, 16, 512)  0           scale_shift_30[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_transpose_30 (Conv2DTran (None, 32, 32, 256)  2097408     activation_35[0][0]              \n","__________________________________________________________________________________________________\n","dense_136 (Dense)               (None, 100)          10100       input_22[0][0]                   \n","__________________________________________________________________________________________________\n","dense_138 (Dense)               (None, 100)          10100       input_22[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_59 (BatchNo (None, 32, 32, 256)  512         conv2d_transpose_30[0][0]        \n","__________________________________________________________________________________________________\n","dense_137 (Dense)               (None, 256)          25856       dense_136[0][0]                  \n","__________________________________________________________________________________________________\n","dense_139 (Dense)               (None, 256)          25856       dense_138[0][0]                  \n","__________________________________________________________________________________________________\n","scale_shift_31 (ScaleShift)     (None, 32, 32, 256)  0           batch_normalization_59[0][0]     \n","                                                                 dense_137[0][0]                  \n","                                                                 dense_139[0][0]                  \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 32, 32, 256)  0           scale_shift_31[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_transpose_31 (Conv2DTran (None, 64, 64, 128)  524416      activation_36[0][0]              \n","__________________________________________________________________________________________________\n","dense_140 (Dense)               (None, 100)          10100       input_22[0][0]                   \n","__________________________________________________________________________________________________\n","dense_142 (Dense)               (None, 100)          10100       input_22[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_60 (BatchNo (None, 64, 64, 128)  256         conv2d_transpose_31[0][0]        \n","__________________________________________________________________________________________________\n","dense_141 (Dense)               (None, 128)          12928       dense_140[0][0]                  \n","__________________________________________________________________________________________________\n","dense_143 (Dense)               (None, 128)          12928       dense_142[0][0]                  \n","__________________________________________________________________________________________________\n","scale_shift_32 (ScaleShift)     (None, 64, 64, 128)  0           batch_normalization_60[0][0]     \n","                                                                 dense_141[0][0]                  \n","                                                                 dense_143[0][0]                  \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 64, 64, 128)  0           scale_shift_32[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_transpose_32 (Conv2DTran (None, 128, 128, 64) 131136      activation_37[0][0]              \n","__________________________________________________________________________________________________\n","dense_144 (Dense)               (None, 100)          10100       input_22[0][0]                   \n","__________________________________________________________________________________________________\n","dense_146 (Dense)               (None, 100)          10100       input_22[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_61 (BatchNo (None, 128, 128, 64) 128         conv2d_transpose_32[0][0]        \n","__________________________________________________________________________________________________\n","dense_145 (Dense)               (None, 64)           6464        dense_144[0][0]                  \n","__________________________________________________________________________________________________\n","dense_147 (Dense)               (None, 64)           6464        dense_146[0][0]                  \n","__________________________________________________________________________________________________\n","scale_shift_33 (ScaleShift)     (None, 128, 128, 64) 0           batch_normalization_61[0][0]     \n","                                                                 dense_145[0][0]                  \n","                                                                 dense_147[0][0]                  \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 128, 128, 64) 0           scale_shift_33[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_transpose_33 (Conv2DTran (None, 256, 256, 3)  3075        activation_38[0][0]              \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 256, 256, 3)  0           conv2d_transpose_33[0][0]        \n","==================================================================================================\n","Total params: 48,953,907\n","Trainable params: 48,945,843\n","Non-trainable params: 8,064\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:Output model_20 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to model_20.\n","WARNING:tensorflow:Output model_20_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to model_20_1.\n","WARNING:tensorflow:Output model_20 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to model_20.\n","WARNING:tensorflow:Output model_20_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to model_20_1.\n","Model: \"model_22\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_24 (InputLayer)           [(None, 100)]        0                                            \n","__________________________________________________________________________________________________\n","input_23 (InputLayer)           [(None, 256, 256, 3) 0                                            \n","__________________________________________________________________________________________________\n","model_21 (Model)                (None, 256, 256, 3)  48953907    input_24[0][0]                   \n","__________________________________________________________________________________________________\n","model_20 (Model)                (None, 1)            44747264    input_23[0][0]                   \n","                                                                 model_21[1][0]                   \n","__________________________________________________________________________________________________\n","tf_op_layer_sub_15 (TensorFlowO [(None, 1)]          0           model_20[1][0]                   \n","                                                                 model_20[2][0]                   \n","__________________________________________________________________________________________________\n","tf_op_layer_sub_16 (TensorFlowO [(None, 256, 256, 3) 0           input_23[0][0]                   \n","                                                                 model_21[1][0]                   \n","__________________________________________________________________________________________________\n","tf_op_layer_strided_slice_5 (Te [(None,)]            0           tf_op_layer_sub_15[0][0]         \n","__________________________________________________________________________________________________\n","tf_op_layer_Abs_5 (TensorFlowOp [(None, 256, 256, 3) 0           tf_op_layer_sub_16[0][0]         \n","__________________________________________________________________________________________________\n","tf_op_layer_pow_5 (TensorFlowOp [(None,)]            0           tf_op_layer_strided_slice_5[0][0]\n","__________________________________________________________________________________________________\n","tf_op_layer_Mean_15 (TensorFlow [(None,)]            0           tf_op_layer_Abs_5[0][0]          \n","__________________________________________________________________________________________________\n","tf_op_layer_mul_11 (TensorFlowO [(None,)]            0           tf_op_layer_pow_5[0][0]          \n","__________________________________________________________________________________________________\n","tf_op_layer_mul_10 (TensorFlowO [(None,)]            0           tf_op_layer_Mean_15[0][0]        \n","__________________________________________________________________________________________________\n","tf_op_layer_Neg_5 (TensorFlowOp [(None,)]            0           tf_op_layer_strided_slice_5[0][0]\n","__________________________________________________________________________________________________\n","tf_op_layer_truediv_5 (TensorFl [(None,)]            0           tf_op_layer_mul_11[0][0]         \n","                                                                 tf_op_layer_mul_10[0][0]         \n","__________________________________________________________________________________________________\n","tf_op_layer_add_5 (TensorFlowOp [(None,)]            0           tf_op_layer_Neg_5[0][0]          \n","                                                                 tf_op_layer_truediv_5[0][0]      \n","__________________________________________________________________________________________________\n","tf_op_layer_Mean_16 (TensorFlow [()]                 0           tf_op_layer_add_5[0][0]          \n","__________________________________________________________________________________________________\n","add_loss_10 (AddLoss)           ()                   0           tf_op_layer_Mean_16[0][0]        \n","==================================================================================================\n","Total params: 89,494,656\n","Trainable params: 44,739,328\n","Non-trainable params: 44,755,328\n","__________________________________________________________________________________________________\n","Model: \"model_23\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_24 (InputLayer)           [(None, 100)]        0                                            \n","__________________________________________________________________________________________________\n","input_23 (InputLayer)           [(None, 256, 256, 3) 0                                            \n","__________________________________________________________________________________________________\n","model_21 (Model)                (None, 256, 256, 3)  48953907    input_24[0][0]                   \n","__________________________________________________________________________________________________\n","model_20 (Model)                (None, 1)            44747264    input_23[0][0]                   \n","                                                                 model_21[2][0]                   \n","__________________________________________________________________________________________________\n","tf_op_layer_sub_17 (TensorFlowO [(None, 1)]          0           model_20[3][0]                   \n","                                                                 model_20[4][0]                   \n","__________________________________________________________________________________________________\n","tf_op_layer_Mean_17 (TensorFlow [()]                 0           tf_op_layer_sub_17[0][0]         \n","__________________________________________________________________________________________________\n","add_loss_11 (AddLoss)           ()                   0           tf_op_layer_Mean_17[0][0]        \n","==================================================================================================\n","Total params: 93,701,171\n","Trainable params: 48,945,843\n","Non-trainable params: 44,755,328\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","iter: 0, d_loss: -2.712168, g_loss: 4.7396727\n","iter: 10, d_loss: -2.7207096, g_loss: 6.6635075\n","iter: 20, d_loss: -2.7005625, g_loss: 5.7353983\n","iter: 30, d_loss: -3.007133, g_loss: 6.3114753\n","iter: 40, d_loss: -2.701951, g_loss: 5.858054\n","iter: 50, d_loss: -2.6322863, g_loss: 5.8611536\n","iter: 60, d_loss: -2.835575, g_loss: 6.2866406\n","iter: 70, d_loss: -2.719362, g_loss: 6.0007877\n","iter: 80, d_loss: -2.7999806, g_loss: 5.144261\n","iter: 90, d_loss: -2.7225752, g_loss: 5.8417163\n","iter: 100, d_loss: -2.6278563, g_loss: 6.170822\n","iter: 110, d_loss: -2.7144272, g_loss: 5.3550606\n","iter: 120, d_loss: -2.7526243, g_loss: 5.7250767\n","iter: 130, d_loss: -2.7189562, g_loss: 5.5071344\n","iter: 140, d_loss: -2.5499372, g_loss: 5.5198135\n","iter: 150, d_loss: -2.827721, g_loss: 5.3600426\n","iter: 160, d_loss: -2.6083236, g_loss: 6.417467\n","iter: 170, d_loss: -2.9068432, g_loss: 5.563636\n","iter: 180, d_loss: -2.8741543, g_loss: 6.905973\n","iter: 190, d_loss: -2.71268, g_loss: 6.1922665\n","iter: 200, d_loss: -2.7345161, g_loss: 6.0426655\n","iter: 210, d_loss: -2.472665, g_loss: 5.1770782\n","iter: 220, d_loss: -2.9154797, g_loss: 5.918762\n","iter: 230, d_loss: -2.8366804, g_loss: 6.6153126\n","iter: 240, d_loss: -2.6472247, g_loss: 6.080198\n","iter: 250, d_loss: -2.7366471, g_loss: 5.693283\n","iter: 260, d_loss: -2.829961, g_loss: 5.879328\n","iter: 270, d_loss: -2.8741345, g_loss: 5.974089\n","iter: 280, d_loss: -2.8077047, g_loss: 6.114296\n","iter: 290, d_loss: -2.822733, g_loss: 6.555375\n","iter: 300, d_loss: -2.6526966, g_loss: 6.7995877\n","iter: 310, d_loss: -2.791135, g_loss: 5.6429863\n","iter: 320, d_loss: -2.7954843, g_loss: 6.1215134\n","iter: 330, d_loss: -2.7925441, g_loss: 6.023508\n","iter: 340, d_loss: -2.6068647, g_loss: 5.48557\n","iter: 350, d_loss: -2.7830396, g_loss: 6.0085297\n","iter: 360, d_loss: -2.711372, g_loss: 5.7039447\n","iter: 370, d_loss: -2.660367, g_loss: 5.4840827\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-b088ad39d70a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mz_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             g_loss = g_train_model.train_on_batch(\n\u001b[0;32m--> 133\u001b[0;31m                 [x_sample, z_sample], None)\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mEMA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mEMAer_g_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"HSUnP-R8OsXa","executionInfo":{"status":"ok","timestamp":1607680490223,"user_tz":-480,"elapsed":973,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}}},"source":["#!rm -rf /content/CASIA-maxpy-clean\n","#!tar xvfJ /content/drive/MyDrive/colab_data/data/CASIA-maxpy-clean.xv\n","!rm -rf /content/samples"],"execution_count":24,"outputs":[]}]}